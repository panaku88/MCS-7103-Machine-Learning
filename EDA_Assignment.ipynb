{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panaku88/MCS-7103-Machine-Learning/blob/main/EDA_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Here I am importing the Google Drive Python Library which is used to connect to colab"
      ],
      "metadata": {
        "id": "bs6PFotHORQh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFStSYFVq4oF",
        "outputId": "8552bf9b-34ff-4b08-a40d-015d5509f8f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Importing the necessary Python Libraries discussed in the report write up"
      ],
      "metadata": {
        "id": "21vvsdUaOrZl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "onf44ur0Clid"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import re\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Reading the raw customer dataset into a Pandas Dataframe and specifying a custom directory (output_path) to store modified dataset"
      ],
      "metadata": {
        "id": "EoLjQm8MO59d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "MZtrVGe9ylRD"
      },
      "outputs": [],
      "source": [
        "raw_dataset = pd.read_csv('/content/drive/MyDrive/MCSC1/dataset/CS_Service_Data.csv')\n",
        "\n",
        "# Specify the path to save the modified/manipulated dataset\n",
        "output_path = '/content/drive/MyDrive/MCSC1/dataset/customer_support_dataset.csv'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Here next code cells, I am assessing the Dataset in order to understand the structure, content and check if there are problems in the dataset"
      ],
      "metadata": {
        "id": "sU_SMQA5PoBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset.head()"
      ],
      "metadata": {
        "id": "SzPF1cVVNHU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset.info()"
      ],
      "metadata": {
        "id": "nQhvhzb5NQNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset.describe()"
      ],
      "metadata": {
        "id": "GxE6fPH_NRee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "lyDMRG30NT--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset.shape"
      ],
      "metadata": {
        "id": "BAdwWPI7NWSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset.columns"
      ],
      "metadata": {
        "id": "nPPh7tfFNX_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. The following are custom Python code to manipulate the dataset. Precisely, we are removing any sensitive information from the data"
      ],
      "metadata": {
        "id": "sWoYmSmZQYhT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "KZelpEMYsVCm"
      },
      "outputs": [],
      "source": [
        "customer_names = {}\n",
        "syllables = ['a', 'e', 'i', 'o', 'u', 'ka', 'ko', 'sa', 'tu', 'ma', 'me', 'mi', 'mo', 'mu', 'ya', 'ye', 'yi', 'yo', 'yu', 'ra', 're', 'ri', 'ro', 'ru', 'wa', 'we', 'wi', 'wo', 'wu']\n",
        "\n",
        "def generate_name(min_length=3, max_length=6):\n",
        "  name = ''\n",
        "  length = random.randint(min_length, max_length)\n",
        "  for i in range(length):\n",
        "    name += random.choice(syllables)\n",
        "  return name.capitalize()\n",
        "\n",
        "def generate_customer_name(row):\n",
        "  name = row['CUSTOMER NAME']\n",
        "  account = row['CUSTOMER ACCOUNT']\n",
        "  if isinstance(name, str):\n",
        "    if account in customer_names:\n",
        "      return customer_names[account]\n",
        "    else:\n",
        "      if 'Mr' in name or 'Ms' in name:\n",
        "        title = random.choice(['Mr', 'Ms'])\n",
        "        first_name = generate_name()\n",
        "        last_name = generate_name()\n",
        "        new_name = f'{title} {first_name} {last_name}'\n",
        "      elif 'Company' in name or 'Ltd' in name or 'Inc' in name:\n",
        "        new_name = generate_name() + ' Inc'\n",
        "      else:\n",
        "        first_name = generate_name()\n",
        "        last_name = generate_name()\n",
        "        new_name = f'{first_name} {last_name}'\n",
        "      customer_names[account] = new_name\n",
        "      return new_name\n",
        "  else:\n",
        "    return name\n",
        "\n",
        "raw_dataset['CUSTOMER NAME'] = raw_dataset.apply(generate_customer_name, axis=1)\n",
        "\n",
        "\n",
        "# Define a function to replace senstive incident ID\n",
        "def replace_rke_with_tt(text):\n",
        "    # Check if the value is a string\n",
        "    if isinstance(text, str):\n",
        "        # Replace any word starting with 'RKE' with 'TT' but keep the rest of the word unchanged\n",
        "        return re.sub(r'\\bRKE(\\w*)\\b', r'TT\\1', text)\n",
        "    else:\n",
        "        # Return the original value if it's not a string\n",
        "        return text\n",
        "\n",
        "\n",
        "def replace_service_plan(text):\n",
        "  if isinstance(text, str):\n",
        "    if re.match(r'CAPPED-BASE: Roke Capped Base', text):\n",
        "      return 'SONIC HOME PRO 25Mbps'\n",
        "    else:\n",
        "      return text\n",
        "  else:\n",
        "    return text\n",
        "\n",
        "def replace_service_plan_ent(text):\n",
        "  if isinstance(text, str):\n",
        "    match = re.search(r'RE(\\d+): Roke Enterprise', text)\n",
        "    if match:\n",
        "      number = match.group(1)\n",
        "      return f'SONIC BUSINESS {number}Mbps'\n",
        "    else:\n",
        "      return text\n",
        "  else:\n",
        "    return text\n",
        "\n",
        "\n",
        "def replace_service_plan_vpn(text):\n",
        "  if isinstance(text, str):\n",
        "    if 'VPN' in text or 'vpn' in text:\n",
        "      random_number = random.randint(1, 100)\n",
        "      return f'SONIC MPLS VPN {random_number}Mbps'\n",
        "    else:\n",
        "      return text\n",
        "  else:\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Data cleanning: After understanding the structure and content in step 5 I realized that it was necessary to clean the data as there were some missing values and some attributes that were not important for my purpose."
      ],
      "metadata": {
        "id": "FcbH9JRhRpyL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuiH_lB3-Ofk",
        "outputId": "38e1ae32-94e2-4828-8a50-459a6ebefa09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The clean_cs_dataset.csv has been created successfully at /content/drive/MyDrive/MCSC1/dataset/customer_support_dataset.csv.\n"
          ]
        }
      ],
      "source": [
        "# Save the modified dataset to the specified path\n",
        "raw_dataset.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"The clean_cs_dataset.csv has been created successfully at {output_path}.\")\n",
        "new_dataset = pd.read_csv('/content/drive/MyDrive/MCSC1/dataset/customer_support_dataset.csv')\n",
        "\n",
        "# Drop rows with 'Not Specified' or 'Not Selected'.\n",
        "new_dataset = new_dataset[new_dataset.applymap(lambda x: 'Not Specified' not in\n",
        "                                               str(x) and 'Not Selected' not in str(x) and 'Shared Bandwidth' not in str(x)).all(axis=1)]\n",
        "\n",
        "# Drop the unnecessary attributes\n",
        "new_dataset = new_dataset.dropna(subset=['TICKET OWNER'])\n",
        "new_dataset = new_dataset.drop('CURRENT STATUS', axis=1)\n",
        "new_dataset = new_dataset.drop('ALLOCATED TIME (HOURS)', axis=1)\n",
        "\n",
        "# here i am calling the above functions to manipulate the dataset\n",
        "raw_dataset['SERVICE PLAN'] = raw_dataset['SERVICE PLAN'].apply(replace_service_plan_vpn)\n",
        "raw_dataset['SERVICE PLAN'] = raw_dataset['SERVICE PLAN'].apply(replace_service_plan_ent)\n",
        "raw_dataset['SERVICE PLAN'] = raw_dataset['SERVICE PLAN'].apply(replace_service_plan)\n",
        "raw_dataset['TICKET NUMBER'] = raw_dataset['TICKET NUMBER'].str.replace(r'^RKE', 'TT', regex=True)\n",
        "\n",
        "\n",
        "# Save the modified dataset to the specified path\n",
        "new_dataset.to_csv(output_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2ufLX72tgtC"
      },
      "outputs": [],
      "source": [
        "new_dataset.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset.head()"
      ],
      "metadata": {
        "id": "-Hi3hIfzN0TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sTv48SgtwBK"
      },
      "outputs": [],
      "source": [
        "new_dataset.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtpbBIvTtyiT"
      },
      "outputs": [],
      "source": [
        "new_dataset.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17z8GC7Bt1eD"
      },
      "outputs": [],
      "source": [
        "new_dataset.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX37QzIpt0Xq"
      },
      "outputs": [],
      "source": [
        "new_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_R8NbHpyuKOv"
      },
      "outputs": [],
      "source": [
        "new_dataset.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGJ18BfLuOBc"
      },
      "outputs": [],
      "source": [
        "new_dataset.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gpTkyz2uT5J"
      },
      "outputs": [],
      "source": [
        "new_dataset.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou1bwRnFucFO"
      },
      "outputs": [],
      "source": [
        "new_dataset.duplicated().sum()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1k2ULLPqYd5sanaOODkz0WPl2wPYz1Vha",
      "authorship_tag": "ABX9TyOTrHRALhZ1yF+HEQLA5+3q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}